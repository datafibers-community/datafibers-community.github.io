<!DOCTYPE html>
<html lang="en-us">

  <head>
  <meta charset="utf-8">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HBase Shell Reference</title>
  <meta name="author" content="" />

  
  <meta name="keywords" content="datafibers, big data, streaming">	
  

  
  <meta name="description" content="DataFibers enterprise open source data bus">	
  

  <meta name="generator" content="Hugo 0.30.2" />

  <link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel='stylesheet' type='text/css'>

  
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

  
  <link href="https://datafibers-community.github.io/css/animate.css" rel="stylesheet">

  
  
    <link href="https://datafibers-community.github.io/css/style.blue.css" rel="stylesheet" id="theme-stylesheet">
  


  
  <link href="https://datafibers-community.github.io/css/custom.css" rel="stylesheet">

  
  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
  <link rel="shortcut icon" href="https://datafibers-community.github.io/img/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" href="https://datafibers-community.github.io/img/apple-touch-icon.png" />
  

  <link href="https://datafibers-community.github.io/css/owl.carousel.css" rel="stylesheet">
  <link href="https://datafibers-community.github.io/css/owl.theme.css" rel="stylesheet">

  <link rel="alternate" href="https://datafibers-community.github.io/index.xml" type="application/rss+xml" title="DataFibers">

  
  <meta property="og:title" content="HBase Shell Reference" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="/blog/2018/04/28/2018-04-28-hbase-shell_example//" />
  <meta property="og:image" content="img/logo.png" />

</head>


  <body>

    <div id="all">

        <header>

          <div class="navbar-affixed-top" data-spy="affix" data-offset-top="200">

    <div class="navbar navbar-default yamm" role="navigation" id="navbar">

        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand home" href="https://datafibers-community.github.io/">
                    <img src="https://datafibers-community.github.io/img/logo.png" alt="HBase Shell Reference logo" height="50" class="hidden-xs hidden-sm">
                    <img src="https://datafibers-community.github.io/img/logo-small.png" alt="HBase Shell Reference logo" class="visible-xs visible-sm">
                    <span class="sr-only">HBase Shell Reference - go to homepage</span>
                </a>
                <div class="navbar-buttons">
                    <button type="button" class="navbar-toggle btn-template-main" data-toggle="collapse" data-target="#navigation">
                      <span class="sr-only">Toggle Navigation</span>
                        <i class="fa fa-align-justify"></i>
                    </button>
                </div>
            </div>
            

            <div class="navbar-collapse collapse" id="navigation">
                <ul class="nav navbar-nav navbar-right">
                  
                  <li class="dropdown">
                    
                    <a href="/">Home</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="http://github.com/datafibers-community/df_data_service/releases/latest">Download</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/community/">Community</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/blog/">Blog</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/training/">Training</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/contact/">Contact</a>
                    
                  </li>
                  
                </ul>
            </div>
            

            <div class="collapse clearfix" id="search">

                <form class="navbar-form" role="search">
                    <div class="input-group">
                        <input type="text" class="form-control" placeholder="Search">
                        <span class="input-group-btn">

                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>

                </span>
                    </div>
                </form>

            </div>
            

        </div>
    </div>
    

</div>




        </header>

        <div id="heading-breadcrumbs">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>HBase Shell Reference</h1>
            </div>
        </div>
    </div>
</div>


        <div id="content">
            <div class="container">

                <div class="row">

                    

                    <div class="col-md-9" id="blog-post">

                        <p class="text-muted text-uppercase mb-small text-right">April 28, 2018</p>

                        <div id="post-content">
                          

<p><p align="left"><img src="https://hbase.apache.org/images/hbase_logo_with_orca_large.png" width="400"></p>
We use this place to collect commonly used HBase shell command for reference. HBase shell is an HBase extensible jruby-based (JIRB) shell to execute some commands(each command represents one functionality) in HBase. HBase shell commands are mainly categorized into 6 parts as follows. Will keep adding more examples here.</p>

<h2 id="1-general-information">1. General Information</h2>

<h4 id="status">status</h4>

<p>Show cluster status. Can be &lsquo;summary&rsquo;, &lsquo;simple&rsquo;, or &lsquo;detailed&rsquo;. The default is &lsquo;summary&rsquo;.</p>

<pre><code>hbase&gt; status
hbase&gt; status 'simple'
hbase&gt; status 'summary'
hbase&gt; status 'detailed'
</code></pre>

<h4 id="version">version</h4>

<p>Output this HBase version.</p>

<pre><code>hbase&gt; version
</code></pre>

<h4 id="whoami">whoami</h4>

<p>Show the current hbase user.Usage:</p>

<pre><code>hbase&gt; whoami
</code></pre>

<h2 id="2-tables-management">2. Tables Management</h2>

<h4 id="alter">alter</h4>

<p>Alter column family schema by passing table name and a specification for new column family schema.</p>

<p>For example, change/add the &lsquo;f1&rsquo; column family in table &lsquo;t1&rsquo; from current value and keep a maximum of 5 cell VERSIONS as follows.</p>

<pre><code>hbase&gt; alter 't1', NAME =&gt; 'f1', VERSIONS =&gt; 5
</code></pre>

<p>You can also operate on several column families together as follows.</p>

<pre><code>hbase&gt; alter 't1', 'f1', {NAME =&gt; 'f2', IN_MEMORY =&gt; true}, {NAME =&gt; 'f3', VERSIONS =&gt; 5}
</code></pre>

<p>To delete the &lsquo;f1&rsquo; column family in table &lsquo;t1&rsquo;, use one of:hbase&gt; alter &lsquo;t1&rsquo;, NAME =&gt; &lsquo;f1&rsquo;, METHOD =&gt; &lsquo;delete&rsquo;</p>

<pre><code>hbase&gt; alter 't1', 'delete' =&gt; 'f1'
</code></pre>

<p>You can also change table-scope attributes like MAX_FILESIZE, READONLY,
MEMSTORE_FLUSHSIZE, DEFERRED_LOG_FLUSH, etc. These can be put at the end;
for example, to change the max size of a region to 128MB, do:</p>

<pre><code>hbase&gt; alter 't1', MAX_FILESIZE =&gt; '134217728'
</code></pre>

<p>You can add a table coprocessor by setting a table coprocessor attribute:</p>

<pre><code>hbase&gt; alter 't1','coprocessor'=&gt;'hdfs:///foo.jar|com.foo.FooRegionObserver|1001|arg1=1,arg2=2'
</code></pre>

<p>Since you can have multiple coprocessors configured for a table, a
sequence number will be automatically appended to the attribute name
to uniquely identify it.</p>

<p>The coprocessor attribute must match the pattern below in order for
the framework to understand how to load the coprocessor classes:</p>

<blockquote>
<p><strong>[coprocessor jar file location] | class name | [priority] | [arguments]</strong></p>
</blockquote>

<p>You can also set configuration settings specific to this table or column family:</p>

<pre><code>hbase&gt; alter 't1', CONFIGURATION =&gt; {'hbase.hregion.scan.loadColumnFamiliesOnDemand' =&gt; 'true'}
hbase&gt; alter 't1', {NAME =&gt; 'f2', CONFIGURATION =&gt; {'hbase.hstore.blockingStoreFiles' =&gt; '10'}}
</code></pre>

<p>You can also remove a table-scope attribute:</p>

<pre><code>hbase&gt; alter 't1', METHOD =&gt; 'table_att_unset', NAME =&gt; 'MAX_FILESIZE'
hbase&gt; alter 't1', METHOD =&gt; 'table_att_unset', NAME =&gt; 'coprocessor$1'
</code></pre>

<p>There could be more than one alteration in one command:</p>

<pre><code>hbase&gt; alter 't1', { NAME =&gt; 'f1', VERSIONS =&gt; 3 }, { MAX_FILESIZE =&gt; '134217728' }, { METHOD =&gt; 'delete', NAME =&gt; 'f2' }, OWNER =&gt; 'johndoe', METADATA =&gt; { 'mykey' =&gt; 'myvalue' }
</code></pre>

<h4 id="create">create</h4>

<p>Create table by passing table name, a specification per column family, and optionally a dictionary of table configuration.</p>

<pre><code>hbase&gt; create 't1', {NAME =&gt; 'f1', VERSIONS =&gt; 5}
hbase&gt; create 't1', {NAME =&gt; 'f1'}, {NAME =&gt; 'f2'}, {NAME =&gt; 'f3'}
hbase&gt; # The above in shorthand would be the following:
hbase&gt; create 't1', 'f1', 'f2', 'f3'
hbase&gt; create 't1', {NAME =&gt; 'f1', VERSIONS =&gt; 1, TTL =&gt; 2592000, BLOCKCACHE =&gt; true}
hbase&gt; create 't1', {NAME =&gt; 'f1', CONFIGURATION =&gt; {'hbase.hstore.blockingStoreFiles' =&gt; '10'}}
</code></pre>

<p>Table configuration options can be put at the end.</p>

<h4 id="describe">describe</h4>

<p>Describe the named table.</p>

<pre><code>hbase&gt; describe 't1'
</code></pre>

<h4 id="disable">disable</h4>

<p>Start disable of named table</p>

<pre><code>hbase&gt; disable 't1'
</code></pre>

<h4 id="disable-all">disable_all</h4>

<p>Disable all of tables matching the given regex</p>

<pre><code>hbase&gt; disable_all 't.*'
</code></pre>

<h4 id="is-disabled">is_disabled</h4>

<p>Verifies Is named table disabled</p>

<pre><code>hbase&gt; is_disabled 't1'
</code></pre>

<h4 id="drop">drop</h4>

<p>Drop the named table. Table must first be disabled</p>

<pre><code>hbase&gt; drop 't1'
</code></pre>

<h4 id="drop-all">drop_all</h4>

<p>Drop all of the tables matching the given regex</p>

<pre><code>hbase&gt; drop_all 't.*'
</code></pre>

<h4 id="enable">enable</h4>

<p>Start enable of named table</p>

<pre><code>hbase&gt; enable 't1'
</code></pre>

<h4 id="enable-all">enable_all</h4>

<p>Enable all of the tables matching the given regex</p>

<pre><code>hbase&gt; enable_all 't.*'
</code></pre>

<h4 id="is-enabled">is_enabled</h4>

<p>Verifies Is named table enabled</p>

<pre><code>hbase&gt; is_enabled 't1'
</code></pre>

<h4 id="exists">exists</h4>

<p>Does the named table exist</p>

<pre><code>hbase&gt; exists 't1'
</code></pre>

<h4 id="list">list</h4>

<p>List all tables in hbase. Optional regular expression parameter could
be used to filter the output</p>

<pre><code>hbase&gt; list
hbase&gt; list 'abc.*'
</code></pre>

<h4 id="show-filters">show_filters</h4>

<p>Show all the filters in hbase.</p>

<pre><code>hbase&gt; show_filters
</code></pre>

<h4 id="alter-status">alter_status</h4>

<p>Get the status of the alter command. Indicates the number of regions of the table that have received the updated schema Pass table name.</p>

<pre><code>hbase&gt; alter_status 't1'
</code></pre>

<h4 id="alter-async">alter_async</h4>

<p>Alter column family schema, does not wait for all regions to receive the schema changes. Pass table name and a dictionary specifying new column
family schema. Dictionaries are described on the main help command output. Dictionary must include name of column family to alter.
To change or add the &lsquo;f1&rsquo; column family in table &lsquo;t1&rsquo; from defaults
to instead keep a maximum of 5 cell VERSIONS, do:</p>

<pre><code>hbase&gt; alter_async 't1', NAME =&gt; 'f1', VERSIONS =&gt; 5
</code></pre>

<p>To delete the &lsquo;f1&rsquo; column family in table &lsquo;t1&rsquo;, do</p>

<pre><code>hbase&gt; alter_async 't1', NAME =&gt; 'f1', METHOD =&gt; 'delete'
</code></pre>

<p>or a shorter version:</p>

<pre><code>hbase&gt; alter_async 't1', 'delete' =&gt; 'f1'
</code></pre>

<p>You can also change table-scope attributes like MAX_FILESIZE, MEMSTORE_FLUSHSIZE, READONLY, and DEFERRED_LOG_FLUSH.
For example, to change the max size of a family to 128MB, do:</p>

<pre><code>hbase&gt; alter 't1', METHOD =&gt; 'table_att', MAX_FILESIZE =&gt; '134217728'
</code></pre>

<p>There could be more than one alteration in one command:</p>

<pre><code>hbase&gt; alter 't1', {NAME =&gt; 'f1'}, {NAME =&gt; 'f2', METHOD =&gt; 'delete'}
</code></pre>

<p>To check if all the regions have been updated, use alter_status <table_name>.</p>

<h2 id="3-data-manipulation">3. Data Manipulation</h2>

<h4 id="count">count</h4>

<p>Count the number of rows in a table. Return value is the number of rows.
This operation may take a LONG time (Run &lsquo;$HADOOP_HOME/bin/hadoop jar
hbase.jar rowcount&rsquo; to run a counting mapreduce job). Current count is shown
every 1000 rows by default. Count interval may be optionally specified. Scan
caching is enabled on count scans by default. Default cache size is 10 rows.
If your rows are small in size, you may want to increase this
parameter. Examples:</p>

<pre><code>hbase&gt; count 't1'
hbase&gt; count 't1', INTERVAL =&gt; 100000
hbase&gt; count 't1', CACHE =&gt; 1000
hbase&gt; count 't1', INTERVAL =&gt; 10, CACHE =&gt; 1000
</code></pre>

<p>The same commands also can be run on a table reference. Suppose you had a reference
t to table &lsquo;t1&rsquo;, the corresponding commands would be:</p>

<pre><code>hbase&gt; t.count
hbase&gt; t.count INTERVAL =&gt; 100000
hbase&gt; t.count CACHE =&gt; 1000
hbase&gt; t.count INTERVAL =&gt; 10, CACHE =&gt; 1000
</code></pre>

<h4 id="delete">delete</h4>

<p>Put a delete cell value at specified table/row/column and optionally
timestamp coordinates. Deletes must match the deleted cell&rsquo;s
coordinates exactly. When scanning, a delete cell suppresses older
versions. To delete a cell from &lsquo;t1&rsquo; at row &lsquo;r1&rsquo; under column &lsquo;c1&rsquo;
marked with the time &lsquo;ts1&rsquo;, do:</p>

<pre><code>hbase&gt; delete 't1', 'r1', 'c1', ts1
</code></pre>

<p>The same command can also be run on a table reference. Suppose you had a reference
t to table &lsquo;t1&rsquo;, the corresponding command would be:hbase&gt; t.delete &lsquo;r1&rsquo;, &lsquo;c1&rsquo;, ts1</p>

<h4 id="deleteall">deleteall</h4>

<p>Delete all cells in a given row; pass a table name, row, and optionally
a column and timestamp. Examples:hbase&gt; deleteall &lsquo;t1&rsquo;, &lsquo;r1&rsquo;</p>

<pre><code>hbase&gt; deleteall 't1', 'r1', 'c1'
hbase&gt; deleteall 't1', 'r1', 'c1', ts1
</code></pre>

<p>The same commands also can be run on a table reference. Suppose you had a reference
t to table &lsquo;t1&rsquo;, the corresponding command would be:</p>

<pre><code>hbase&gt; t.deleteall 'r1'
hbase&gt; t.deleteall 'r1', 'c1'
hbase&gt; t.deleteall 'r1', 'c1', ts1
</code></pre>

<h4 id="get">get</h4>

<p>Get row or cell contents; pass table name, row, and optionally
a dictionary of column(s), timestamp, timerange and versions. Examples:</p>

<pre><code>hbase&gt; get 't1', 'r1'
hbase&gt; get 't1', 'r1', {TIMERANGE =&gt; [ts1, ts2]}
hbase&gt; get 't1', 'r1', {COLUMN =&gt; 'c1'}
hbase&gt; get 't1', 'r1', {COLUMN =&gt; ['c1', 'c2', 'c3']}
hbase&gt; get 't1', 'r1', {COLUMN =&gt; 'c1', TIMESTAMP =&gt; ts1}
hbase&gt; get 't1', 'r1', {COLUMN =&gt; 'c1', TIMERANGE =&gt; [ts1, ts2], VERSIONS =&gt; 4}
hbase&gt; get 't1', 'r1', {COLUMN =&gt; 'c1', TIMESTAMP =&gt; ts1, VERSIONS =&gt; 4}
hbase&gt; get 't1', 'r1', {FILTER =&gt; “ValueFilter(=, 'binary:abc')”}
hbase&gt; get 't1', 'r1', 'c1'
hbase&gt; get 't1', 'r1', 'c1', 'c2'
hbase&gt; get 't1', 'r1', ['c1', 'c2']
</code></pre>

<p>Besides the default &lsquo;toStringBinary&rsquo; format, &lsquo;get&rsquo; also supports custom formatting by
column. A user can define a FORMATTER by adding it to the column name in the get
specification. The FORMATTER can be stipulated:</p>

<ol>
<li>either as a org.apache.hadoop.hbase.util.Bytes method name (e.g, toInt, toString)</li>
<li>or as a custom class followed by method name: e.g. &lsquo;c(MyFormatterClass).format&rsquo;.Example formatting cf:qualifier1 and cf:qualifier2 both as Integers:
<code>
hbase&gt; get 't1', 'r1' {COLUMN =&gt; ['cf:qualifier1:toInt','cf:qualifier2:c(org.apache.hadoop.hbase.util.Bytes).toInt'] }
</code></li>
</ol>

<p>Note that you can specify a FORMATTER by column only (cf:qualifer). You cannot specify
a FORMATTER for all columns of a column family.The same commands also can be run on a reference to a table (obtained via get_table or
create_table). Suppose you had a reference t to table &lsquo;t1&rsquo;, the corresponding commands
would be:</p>

<pre><code>hbase&gt; t.get 'r1'
hbase&gt; t.get 'r1', {TIMERANGE =&gt; [ts1, ts2]}
hbase&gt; t.get 'r1', {COLUMN =&gt; 'c1'}
hbase&gt; t.get 'r1', {COLUMN =&gt; ['c1', 'c2', 'c3']}
hbase&gt; t.get 'r1', {COLUMN =&gt; 'c1', TIMESTAMP =&gt; ts1}
hbase&gt; t.get 'r1', {COLUMN =&gt; 'c1', TIMERANGE =&gt; [ts1, ts2], VERSIONS =&gt; 4}
hbase&gt; t.get 'r1', {COLUMN =&gt; 'c1', TIMESTAMP =&gt; ts1, VERSIONS =&gt; 4}
hbase&gt; t.get 'r1', {FILTER =&gt; “ValueFilter(=, 'binary:abc')”}
hbase&gt; t.get 'r1', 'c1'
hbase&gt; t.get 'r1', 'c1', 'c2'
hbase&gt; t.get 'r1', ['c1', 'c2']
</code></pre>

<h4 id="get-counter">get_counter</h4>

<p>Return a counter cell value at specified table/row/column coordinates.
A cell cell should be managed with atomic increment function oh HBase
and the data should be binary encoded. Example:</p>

<pre><code>hbase&gt; get_counter 't1', 'r1', 'c1'
</code></pre>

<p>The same commands also can be run on a table reference. Suppose you had a reference
t to table &lsquo;t1&rsquo;, the corresponding command would be:</p>

<pre><code>hbase&gt; t.get_counter 'r1', 'c1'
</code></pre>

<h4 id="incr">incr</h4>

<p>Increments a cell &lsquo;value&rsquo; at specified table/row/column coordinates.
To increment a cell value in table &lsquo;t1&rsquo; at row &lsquo;r1&rsquo; under column
&lsquo;c1&rsquo; by 1 (can be omitted) or 10 do:</p>

<pre><code>hbase&gt; incr 't1', 'r1', 'c1'
hbase&gt; incr 't1', 'r1', 'c1', 1
hbase&gt; incr 't1', 'r1', 'c1', 10
</code></pre>

<p>The same commands also can be run on a table reference. Suppose you had a reference
t to table &lsquo;t1&rsquo;, the corresponding command would be:</p>

<pre><code>hbase&gt; t.incr 'r1', 'c1'
hbase&gt; t.incr 'r1', 'c1', 1
hbase&gt; t.incr 'r1', 'c1', 10
</code></pre>

<h4 id="put">put</h4>

<p>Put a cell &lsquo;value&rsquo; at specified table/row/column and optionally
timestamp coordinates. To put a cell value into table &lsquo;t1&rsquo; at
row &lsquo;r1&rsquo; under column &lsquo;c1&rsquo; marked with the time &lsquo;ts1&rsquo;, do:</p>

<pre><code>hbase&gt; put 't1', 'r1', 'c1', 'value', ts1
</code></pre>

<p>The same commands also can be run on a table reference. Suppose you had a reference t to table &lsquo;t1&rsquo;, the corresponding command would be:</p>

<pre><code>hbase&gt; t.put 'r1', 'c1', 'value', ts1
</code></pre>

<h4 id="scan">scan</h4>

<p>Scan a table; pass table name and optionally a dictionary of scanner
specifications. Scanner specifications may include one or more of:
TIMERANGE, FILTER, LIMIT, STARTROW, STOPROW, TIMESTAMP, MAXLENGTH,
or COLUMNS, CACHEIf no columns are specified, all columns will be scanned.
To scan all members of a column family, leave the qualifier empty as in
&lsquo;col_family:&lsquo;.The filter can be specified in two ways:</p>

<ol>
<li>Using a filterString – more information on this is available in the
Filter Language document attached to the HBASE-4176 JIRA</li>
<li>Using the entire package name of the filter.</li>
</ol>

<p>Some examples:</p>

<pre><code>hbase&gt; scan '.META.'
hbase&gt; scan '.META.', {COLUMNS =&gt; 'info:regioninfo'}
hbase&gt; scan 't1', {COLUMNS =&gt; ['c1', 'c2'], LIMIT =&gt; 10, STARTROW =&gt; 'xyz'}
hbase&gt; scan 't1', {COLUMNS =&gt; 'c1', TIMERANGE =&gt; [1303668804, 1303668904]}
hbase&gt; scan 't1', {FILTER =&gt; “(PrefixFilter ('row2') AND (QualifierFilter (&gt;=, 'binary:xyz'))) AND (TimestampsFilter ( 123, 456))”}
hbase&gt; scan 't1', {FILTER =&gt;org.apache.hadoop.hbase.filter.ColumnPaginationFilter.new(1, 0)}
</code></pre>

<p>For experts, there is an additional option — CACHE_BLOCKS — which
switches block caching for the scanner on (true) or off (false). By
default it is enabled. Examples:</p>

<pre><code>hbase&gt; scan 't1', {COLUMNS =&gt; ['c1', 'c2'], CACHE_BLOCKS =&gt; false}
</code></pre>

<p>Also for experts, there is an advanced option — RAW — which instructs the
scanner to return all cells (including delete markers and uncollected deleted
cells). This option cannot be combined with requesting specific COLUMNS.
Disabled by default. Example:</p>

<pre><code>hbase&gt; scan 't1', {RAW =&gt; true, VERSIONS =&gt; 10}
</code></pre>

<p>Besides the default &lsquo;toStringBinary&rsquo; format, &lsquo;scan&rsquo; supports custom formatting
by column. A user can define a FORMATTER by adding it to the column name in
the scan specification. The FORMATTER can be stipulated:</p>

<ol>
<li>either as a org.apache.hadoop.hbase.util.Bytes method name (e.g, toInt, toString)</li>
<li>or as a custom class followed by method name: e.g. &lsquo;c(MyFormatterClass).format&rsquo;.</li>
</ol>

<p>Example formatting cf:qualifier1 and cf:qualifier2 both as Integers:</p>

<pre><code>hbase&gt; scan 't1', {COLUMNS =&gt; ['cf:qualifier1:toInt','cf:qualifier2:c(org.apache.hadoop.hbase.util.Bytes).toInt'] }
</code></pre>

<p>Note that you can specify a FORMATTER by column only (cf:qualifer). You cannot
specify a FORMATTER for all columns of a column family.</p>

<p>Scan can also be used directly from a table, by first getting a reference to a
table, like such:</p>

<pre><code>hbase&gt; t = get_table 't'
hbase&gt; t.scan
</code></pre>

<p>Note in the above situation, you can still provide all the filtering, columns,options, etc as described above.</p>

<h4 id="truncate">truncate</h4>

<p>Disables, drops and recreates the specified table.
Examples:</p>

<pre><code>hbase&gt;truncate 't1'
</code></pre>

<h2 id="4-surgery-tools">4. Surgery Tools</h2>

<h4 id="assign">assign</h4>

<p>Assign a region. Use with caution. If region already assigned, this command will do a force reassign. For experts only.
Examples:</p>

<pre><code>hbase&gt; assign 'REGION_NAME'
</code></pre>

<h4 id="balancer">balancer</h4>

<p>Trigger the cluster balancer. Returns true if balancer ran and was able to
tell the region servers to unassign all the regions to balance (the re-assignment itself is async).
Otherwise false (Will not run if regions in transition).
Examples:</p>

<pre><code>hbase&gt; balancer
</code></pre>

<p>balance_switch  Enable/Disable balancer. Returns previous balancer state.
Examples:</p>

<pre><code>hbase&gt; balance_switch true
hbase&gt; balance_switch false
</code></pre>

<h4 id="close-region">close_region</h4>

<p>Close a single region. Ask the master to close a region out on the cluster
or if &lsquo;SERVER_NAME&rsquo; is supplied, ask the designated hosting regionserver to
close the region directly. Closing a region, the master expects &lsquo;REGIONNAME&rsquo;
to be a fully qualified region name. When asking the hosting regionserver to
directly close a region, you pass the regions&rsquo; encoded name only. A region
name looks like this:TestTable,0094429456,1289497600452.527db22f95c8a9e0116f0cc13c680396.The trailing period is part of the regionserver name. A region&rsquo;s encoded name
is the hash at the end of a region name; e.g. 527db22f95c8a9e0116f0cc13c680396
(without the period). A &lsquo;SERVER_NAME&rsquo; is its host, port plus startcode. For
example: host187.example.com,60020,1289493121758 (find servername in master ui
or when you do detailed status in shell). This command will end up running
close on the region hosting regionserver. The close is done without the
master&rsquo;s involvement (It will not know of the close). Once closed, region will
stay closed. Use assign to reopen/reassign. Use unassign or move to assign
the region elsewhere on cluster. Use with caution. For experts only.
Examples:</p>

<pre><code>hbase&gt; close_region 'REGIONNAME'
hbase&gt; close_region 'REGIONNAME', 'SERVER_NAME'
</code></pre>

<h4 id="compact">compact</h4>

<p>Compact all regions in passed table or pass a region row
to compact an individual region. You can also compact a single column
family within a region.</p>

<p>Examples:</p>

<p>Compact all regions in a table:</p>

<pre><code>hbase&gt; compact 't1'
</code></pre>

<p>Compact an entire region:</p>

<pre><code>hbase&gt; compact 'r1'
</code></pre>

<p>Compact only a column family within a region:</p>

<pre><code>hbase&gt; compact 'r1', 'c1'
</code></pre>

<p>Compact a column family within a table:</p>

<pre><code>hbase&gt; compact 't1', 'c1'
</code></pre>

<h4 id="flush">flush</h4>

<p>Flush all regions in passed table or pass a region row to
flush an individual region. For example:</p>

<pre><code>hbase&gt; flush 'TABLENAME'
hbase&gt; flush 'REGIONNAME'
</code></pre>

<h4 id="major-compact">major_compact</h4>

<p>Run major compaction on passed table or pass a region row
to major compact an individual region. To compact a single
column family within a region specify the region name
followed by the column family name.</p>

<p>Examples:</p>

<p>Compact all regions in a table:</p>

<pre><code>hbase&gt; major_compact 't1'
</code></pre>

<p>Compact an entire region:</p>

<pre><code>hbase&gt; major_compact 'r1'
</code></pre>

<p>Compact a single column family within a region:</p>

<pre><code>hbase&gt; major_compact 'r1', 'c1'
</code></pre>

<p>Compact a single column family within a table:</p>

<pre><code>hbase&gt; major_compact 't1', 'c1'
</code></pre>

<h4 id="move">move</h4>

<p>Move a region. Optionally specify target regionserver else we choose one
at random. NOTE: You pass the encoded region name, not the region name so
this command is a little different to the others. The encoded region name
is the hash suffix on region names: e.g. if the region name were
TestTable,0094429456,1289497600452.527db22f95c8a9e0116f0cc13c680396. then
the encoded region name portion is 527db22f95c8a9e0116f0cc13c680396
A server name is its host, port plus startcode. For example:
host187.example.com,60020,1289493121758</p>

<p>Examples:</p>

<pre><code>hbase&gt; move 'ENCODED_REGIONNAME'
hbase&gt; move 'ENCODED_REGIONNAME', 'SERVER_NAME'
</code></pre>

<h4 id="split">split</h4>

<p>Split entire table or pass a region to split individual region. With the
second parameter, you can specify an explicit split key for the region.</p>

<p>Examples:</p>

<pre><code>split 'tableName'
split 'regionName' # format: 'tableName,startKey,id'
split 'tableName', 'splitKey'
split 'regionName', 'splitKey'
</code></pre>

<h4 id="unassign">unassign</h4>

<p>Unassign a region. Unassign will close region in current location and then
reopen it again. Pass &lsquo;true&rsquo; to force the unassignment (&lsquo;force&rsquo; will clear
all in-memory state in master before the reassign. If results in
double assignment use hbck -fix to resolve. To be used by experts).
Use with caution. For expert use only.</p>

<p>Examples:</p>

<pre><code>hbase&gt; unassign 'REGIONNAME'
hbase&gt; unassign 'REGIONNAME', true
</code></pre>

<h4 id="hlog-roll">hlog_roll</h4>

<p>Roll the log writer. That is, start writing log messages to a new file.
The name of the regionserver should be given as the parameter. A
&lsquo;server_name&rsquo; is the host, port plus startcode of a regionserver. For
example: host187.example.com,60020,1289493121758 (find servername in
master ui or when you do detailed status in shell)</p>

<pre><code>hbase&gt;hlog_roll
</code></pre>

<h4 id="zk-dump">zk_dump</h4>

<p>Dump status of HBase cluster as seen by ZooKeeper.</p>

<p>Example:</p>

<pre><code>hbase&gt;zk_dump
</code></pre>

<h2 id="5-cluster-replication-tools">5. Cluster Replication Tools</h2>

<h4 id="add-peer">add_peer</h4>

<p>Add a peer cluster to replicate to, the id must be a short and
the cluster key is composed like this:
hbase.zookeeper.quorum:hbase.zookeeper.property.clientPort:zookeeper.znode.parent
This gives a full path for HBase to connect to another cluster.</p>

<p>Examples:</p>

<pre><code>hbase&gt; add_peer '1', “server1.cie.com:2181:/hbase”
hbase&gt; add_peer '2', “zk1,zk2,zk3:2182:/hbase-prod”
</code></pre>

<h4 id="remove-peer">remove_peer</h4>

<p>Stops the specified replication stream and deletes all the meta
information kept about it.</p>

<p>Examples:</p>

<pre><code>hbase&gt; remove_peer '1'
</code></pre>

<h4 id="list-peers">list_peers</h4>

<p>List all replication peer clusters.
hbase&gt; list_peers
enable_peer Restarts the replication to the specified peer cluster,
continuing from where it was disabled.</p>

<p>Examples:
hbase&gt; enable_peer &lsquo;1&rsquo;</p>

<h4 id="disable-peer">disable_peer</h4>

<p>Stops the replication stream to the specified cluster, but still
keeps track of new edits to replicate.</p>

<p>Examples:</p>

<pre><code>hbase&gt; disable_peer '1'
</code></pre>

<h4 id="start-replication">start_replication</h4>

<p>Restarts all the replication features. The state in which each stream starts in is undetermined.
WARNING:
start/stop replication is only meant to be used in critical load situations.</p>

<p>Examples:</p>

<pre><code>hbase&gt; start_replication
</code></pre>

<h4 id="stop-replication">stop_replication</h4>

<p>Stops all the replication features. The state in which each stream stops in is undetermined.
WARNING:
start/stop replication is only meant to be used in critical load situations.</p>

<p>Examples:</p>

<pre><code>hbase&gt; stop_replication
</code></pre>

<h2 id="6-security-tools">6. Security Tools</h2>

<h4 id="grant">grant</h4>

<p>Grant users specific rights.
Syntax : grantpermissions is either zero or more letters from the set “RWXCA”.
READ(&lsquo;R&rsquo;), WRITE(&lsquo;W&rsquo;), EXEC(&lsquo;X&rsquo;), CREATE(&lsquo;C&rsquo;), ADMIN(&lsquo;A&rsquo;). For example:</p>

<pre><code>hbase&gt; grant 'bobsmith', 'RWXCA'
hbase&gt; grant 'bobsmith', 'RW', 't1', 'f1', 'col1'
</code></pre>

<h4 id="revoke">revoke</h4>

<p>Revoke a user&rsquo;s access rights.</p>

<pre><code>hbase&gt; revoke 'bobsmith', 't1', 'f1', 'col1'
</code></pre>

<h4 id="user-permission">user_permission</h4>

<p>Show all permissions for the particular user.
Syntax : user_permission</p>

<p>For example:</p>

<pre><code>hbase&gt; user_permission
hbase&gt; user_permission 'table1'
</code></pre>

                        </div>
                        
                        
                        <div id="comments">
                            <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "sparkera" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
                        </div>
                        

                    </div>
                    

                    

                    

                    <div class="col-md-3">

                        

                        

<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Search</h3>
    </div>

    <div class="panel-body">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" role="search">
            <div class="input-group">
                <input type="search" name="q" class="form-control" placeholder="Search">
                <input type="hidden" name="sitesearch" value="https://datafibers-community.github.io/">
                <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>
                </span>
            </div>
        </form>
    </div>
</div>







<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Categories</h3>
    </div>

    <div class="panel-body">
        <ul class="nav nav-pills nav-stacked">
            
            <li><a href="https://datafibers-community.github.io/categories/article">article (18)</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/categories/digest">digest (10)</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/categories/release">release (3)</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/categories/review">review (1)</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/categories/training">training (1)</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/categories/tutorial">tutorial (1)</a>
            </li>
            
        </ul>
    </div>
</div>








<div class="panel sidebar-menu">
    <div class="panel-heading">
      <h3 class="panel-title">Tags</h3>
    </div>

    <div class="panel-body">
        <ul class="tag-cloud">
            
            <li><a href="https://datafibers-community.github.io/tags/apache"><i class="fa fa-tags"></i> apache</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/big-data"><i class="fa fa-tags"></i> big-data</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/cloud"><i class="fa fa-tags"></i> cloud</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/datafibers"><i class="fa fa-tags"></i> datafibers</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/flink"><i class="fa fa-tags"></i> flink</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/git"><i class="fa fa-tags"></i> git</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/hadoop"><i class="fa fa-tags"></i> hadoop</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/hbase"><i class="fa fa-tags"></i> hbase</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/hive"><i class="fa fa-tags"></i> hive</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/k8s"><i class="fa fa-tags"></i> k8s</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/kafka"><i class="fa fa-tags"></i> kafka</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/machine-learning"><i class="fa fa-tags"></i> machine-learning</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/nosql"><i class="fa fa-tags"></i> nosql</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/redish"><i class="fa fa-tags"></i> redish</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/scala"><i class="fa fa-tags"></i> scala</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/spark"><i class="fa fa-tags"></i> spark</a>
            </li>
            
        </ul>
    </div>
</div>






                        

                    </div>
                    

                    

                </div>
                

            </div>
            
        </div>
        

        <footer id="footer">
    <div class="container">

        
        <div class="col-md-4 col-sm-6">
            <h4>About us</h4>

            DataFibers are expertises by applying its cutting edge big data technologies and solutions on enterprise big data centric use cases.

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

        <div class="col-md-4 col-sm-6">

             
            <h4>Recent posts</h4>

            <div class="blog-entries">
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="https://datafibers-community.github.io/blog/2023/07/01/2023-07-31-leading-cloud-technology-stack/">
                          
                            <img src="https://datafibers-community.github.io//img/banners/cloud_computing.png" class="img-responsive" alt="Leading Cloud Tech. Stack Comparison">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="https://datafibers-community.github.io/blog/2023/07/01/2023-07-31-leading-cloud-technology-stack/">Leading Cloud Tech. Stack Comparison</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="https://datafibers-community.github.io/blog/2021/06/19/2021-06-19-embracing-kubernetes-goodbye-spring-cloud-copy/">
                          
                            <img src="https://datafibers-community.github.io//img/banners/k8s01.png" class="img-responsive" alt="Embracing Kubernetes, Goodbye Spring Cloud">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="https://datafibers-community.github.io/blog/2021/06/19/2021-06-19-embracing-kubernetes-goodbye-spring-cloud-copy/">Embracing Kubernetes, Goodbye Spring Cloud</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="https://datafibers-community.github.io/blog/2021/04/28/2021-04-28-spark-sql-in-depth-copy/">
                          
                            <img src="https://datafibers-community.github.io//img/banners/spark_sql_title.png" class="img-responsive" alt="Spark SQL in Depth">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="https://datafibers-community.github.io/blog/2021/04/28/2021-04-28-spark-sql-in-depth-copy/">Spark SQL in Depth</a></h5>
                    </div>
                </div>
                
            </div>

            <hr class="hidden-md hidden-lg">
             

        </div>
        

        
        <div class="col-md-4 col-sm-6">

          <h4>Contact</h4>

            <p><p><strong>DataFibers.</strong>
        <br>7030 Woodbine Avenue,
        <br>L3R 6G2
        <br>Ontario, Markham
        <br>Canadar
        <br>
        <br>
        <strong>Tel: +1 (647) 960-8578</strong>
        <br></p>


            <a href="/contact" class="btn btn-small btn-template-main">Go to contact page</a>

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

    </div>
    
</footer>







<div id="copyright">
    <div class="container">
        <div class="col-md-12">
            
            <p class="pull-left">Copyright (c) 2020, DataFibers all rights reserved.</p>
			<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
		    <span id="busuanzi_container_site_pv"> <span id="busuanzi_value_site_pv"></span> visits</span>
            
            <p class="pull-right">
              Template by <a href="http://bootstrapious.com/free-templates">Bootstrapious</a>.
              

              Powered by <a href="https://gohugo.io/">Hugo</a>
            </p>
        </div>
    </div>
</div>





    </div>
    

    
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-40213017-3', 'auto');
ga('send', 'pageview');
</script>

<script src="//code.jquery.com/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js"></script>

<script src="//maps.googleapis.com/maps/api/js?key=AIzaSyCksU3IZTuUK6fA-doQUfQ4KcYm7mB_vlk&v=3.exp"></script>

<script src="https://datafibers-community.github.io/js/hpneo.gmaps.js"></script>
<script src="https://datafibers-community.github.io/js/gmaps.init.js"></script>
<script src="https://datafibers-community.github.io/js/front.js"></script>


<script src="https://datafibers-community.github.io/js/owl.carousel.min.js"></script>


<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-55ccd57a1c1b9515"></script>
  </body>
</html>
