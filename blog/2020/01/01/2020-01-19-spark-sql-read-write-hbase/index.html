<!DOCTYPE html>
<html lang="en-us">

  <head>
  <meta charset="utf-8">
  <meta name="robots" content="all,follow">
  <meta name="googlebot" content="index,follow,snippet,archive">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Spark SQL Read/Write HBase</title>
  <meta name="author" content="" />

  
  <meta name="keywords" content="datafibers, big data, streaming">	
  

  
  <meta name="description" content="DataFibers enterprise open source data bus">	
  

  <meta name="generator" content="Hugo 0.30.2" />

  <link href='//fonts.googleapis.com/css?family=Roboto:400,100,100italic,300,300italic,500,700,800' rel='stylesheet' type='text/css'>

  
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

  
  <link href="https://datafibers-community.github.io/css/animate.css" rel="stylesheet">

  
  
    <link href="https://datafibers-community.github.io/css/style.blue.css" rel="stylesheet" id="theme-stylesheet">
  


  
  <link href="https://datafibers-community.github.io/css/custom.css" rel="stylesheet">

  
  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  

  
  <link rel="shortcut icon" href="https://datafibers-community.github.io/img/favicon.ico" type="image/x-icon" />
  <link rel="apple-touch-icon" href="https://datafibers-community.github.io/img/apple-touch-icon.png" />
  

  <link href="https://datafibers-community.github.io/css/owl.carousel.css" rel="stylesheet">
  <link href="https://datafibers-community.github.io/css/owl.theme.css" rel="stylesheet">

  <link rel="alternate" href="https://datafibers-community.github.io/index.xml" type="application/rss+xml" title="DataFibers">

  
  <meta property="og:title" content="Spark SQL Read/Write HBase" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="/blog/2020/01/01/2020-01-19-spark-sql-read-write-hbase//" />
  <meta property="og:image" content="img/logo.png" />

</head>


  <body>

    <div id="all">

        <header>

          <div class="navbar-affixed-top" data-spy="affix" data-offset-top="200">

    <div class="navbar navbar-default yamm" role="navigation" id="navbar">

        <div class="container">
            <div class="navbar-header">
                <a class="navbar-brand home" href="https://datafibers-community.github.io/">
                    <img src="https://datafibers-community.github.io/img/logo.png" alt="Spark SQL Read/Write HBase logo" height="50" class="hidden-xs hidden-sm">
                    <img src="https://datafibers-community.github.io/img/logo-small.png" alt="Spark SQL Read/Write HBase logo" class="visible-xs visible-sm">
                    <span class="sr-only">Spark SQL Read/Write HBase - go to homepage</span>
                </a>
                <div class="navbar-buttons">
                    <button type="button" class="navbar-toggle btn-template-main" data-toggle="collapse" data-target="#navigation">
                      <span class="sr-only">Toggle Navigation</span>
                        <i class="fa fa-align-justify"></i>
                    </button>
                </div>
            </div>
            

            <div class="navbar-collapse collapse" id="navigation">
                <ul class="nav navbar-nav navbar-right">
                  
                  <li class="dropdown">
                    
                    <a href="/">Home</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="http://github.com/datafibers-community/df_data_service/releases/latest">Download</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/community/">Community</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/blog/">Blog</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/training/">Training</a>
                    
                  </li>
                  
                  <li class="dropdown">
                    
                    <a href="/contact/">Contact</a>
                    
                  </li>
                  
                </ul>
            </div>
            

            <div class="collapse clearfix" id="search">

                <form class="navbar-form" role="search">
                    <div class="input-group">
                        <input type="text" class="form-control" placeholder="Search">
                        <span class="input-group-btn">

                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>

                </span>
                    </div>
                </form>

            </div>
            

        </div>
    </div>
    

</div>




        </header>

        <div id="heading-breadcrumbs">
    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h1>Spark SQL Read/Write HBase</h1>
            </div>
        </div>
    </div>
</div>


        <div id="content">
            <div class="container">

                <div class="row">

                    

                    <div class="col-md-9" id="blog-post">

                        <p class="text-muted text-uppercase mb-small text-right">January 1, 2020</p>

                        <div id="post-content">
                          

<hr />

<p>Apache Spark and Apache HBase are very commonly used big data frameworks. In many senarios, we need to use Spark to query and analyze the big volumn of data in HBase. Spark has wider support to read data as dataset from many kinds of data source. To read from HBase, Spark provides TableInputFormat, which as following disadvantages.</p>

<ul>
<li>There is only on scan triggerred in each task to read from HBase</li>
<li>TableInputFormat does not support BulkGet</li>
<li>Cannot leverage the optimization from Spark SQL catalyst</li>
</ul>

<p>Considering the above points above, there is another choice by using Hortonworks/Cloudera <a href="https://github.com/hortonworks-spark/shc">Apache Spark—Apache HBase Connector</a> short for (SHC). By using SHC, we can use Spark SQL directly load dataframe data into HBase or query data from HBase. When querying HBase, it leverages the Spark Catalyst for query optimization, such as partition pruning, column pruning, predicate pushdown, data locality, and so on. As a result, the performance using Spark to query HBase has great improvment.</p>

<p>Note：SHC also supports writing DataFrame into HBase. However, there is no much performance improvment, so we do not focus on this part.</p>

<h3 id="how-shc-improve-the-query-performance">How SHC Improve the Query Performance</h3>

<p>SHC mainly uses following ways for performance tuning to narrow down the HBase scanning scops.</p>

<h4 id="1-convert-rowkey-based-search-to-get">1. Convert Rowkey based search to get</h4>

<p>As we all know that search using <strong>scan</strong> in HBase is very efficient. If the search condition is RowKey based，we should able to change it using <strong>get</strong>.</p>

<p>For example, with predefined HBase catalog as follows.</p>

<pre><code>val catalog = s&quot;&quot;&quot;{
  |&quot;table&quot;:{&quot;namespace&quot;:&quot;default&quot;, &quot;name&quot;:&quot;iteblog&quot;, &quot;tableCoder&quot;:&quot;PrimitiveType&quot;},
  |&quot;rowkey&quot;:&quot;key&quot;,
  |&quot;columns&quot;:{
    |&quot;col0&quot;:{&quot;cf&quot;:&quot;rowkey&quot;, &quot;col&quot;:&quot;id&quot;, &quot;type&quot;:&quot;int&quot;},
    |&quot;col1&quot;:{&quot;cf&quot;:&quot;cf1&quot;, &quot;col&quot;:&quot;col1&quot;, &quot;type&quot;:&quot;boolean&quot;},
    |&quot;col2&quot;:{&quot;cf&quot;:&quot;cf2&quot;, &quot;col&quot;:&quot;col2&quot;, &quot;type&quot;:&quot;double&quot;},
    |&quot;col3&quot;:{&quot;cf&quot;:&quot;cf3&quot;, &quot;col&quot;:&quot;col3&quot;, &quot;type&quot;:&quot;float&quot;},
    |&quot;col4&quot;:{&quot;cf&quot;:&quot;cf4&quot;, &quot;col&quot;:&quot;col4&quot;, &quot;type&quot;:&quot;int&quot;},
    |&quot;col5&quot;:{&quot;cf&quot;:&quot;cf5&quot;, &quot;col&quot;:&quot;col5&quot;, &quot;type&quot;:&quot;bigint&quot;},
    |&quot;col6&quot;:{&quot;cf&quot;:&quot;cf6&quot;, &quot;col&quot;:&quot;col6&quot;, &quot;type&quot;:&quot;smallint&quot;},
    |&quot;col7&quot;:{&quot;cf&quot;:&quot;cf7&quot;, &quot;col&quot;:&quot;col7&quot;, &quot;type&quot;:&quot;string&quot;},
    |&quot;col8&quot;:{&quot;cf&quot;:&quot;cf8&quot;, &quot;col&quot;:&quot;col8&quot;, &quot;type&quot;:&quot;tinyint&quot;}
  |}
|}&quot;&quot;&quot;.stripMargin
</code></pre>

<p>If we have flollowing search,</p>

<pre><code>val df = withCatalog(catalog)
df.createOrReplaceTempView(&quot;iteblog_table&quot;)
sqlContext.sql(&quot;select * from iteblog_table where id = 1&quot;)
sqlContext.sql(&quot;select * from iteblog_table where id = 1 or id = 2&quot;)
sqlContext.sql(&quot;select * from iteblog_table where id in (1, 2)&quot;)
</code></pre>

<p>Because the search condition is aginst the RowKey, we can change it using <strong>get</strong> or <strong>BulkGet</strong>. The 1st SQL query is working as follows.
<p align="center"><img src="https://s.iteblog.com/pic/hbase/shc_get-iteblog.png" width="800"></p></p>

<p>The 2nd and 3rd query are equal. It will convert <code>key in (x1, x2, x3..)</code> to <code>(key == x1) or (key == x2) or ...</code> as follows.
<p align="center"><img src="https://s.iteblog.com/pic/hbase/shc_bulkget-iteblog.png" width="800"></p></p>

<p>if the query has both filtering on RowKey and other columns (see below example),</p>

<pre><code>sqlContext.sql(&quot;select id, col6, col8 from iteblog_table where id = 1 and col7 = 'xxx'&quot;)
</code></pre>

<p>it will convert to the following search.</p>

<pre><code>val filter = new SingleColumnValueFilter(
              Bytes.toBytes(&quot;cf7&quot;), Bytes.toBytes(&quot;col7 &quot;)
              CompareOp.EQUAL,
             Bytes.toBytes(&quot;xxx&quot;))
 
val g = new Get(Bytes.toBytes(1))
g.addColumn(Bytes.toBytes(&quot;cf6&quot;), Bytes.toBytes(&quot;col6&quot;))
g.addColumn(Bytes.toBytes(&quot;cf8&quot;), Bytes.toBytes(&quot;col8&quot;))
g.setFilter(filter)
</code></pre>

<p>If we have multiple and conditions, it all use<strong>SingleColumnValueFilter</strong> for filtering.
If we have following search/query,</p>

<pre><code>sqlContext.sql(&quot;select id, col6, col8 from iteblog_table where id = 1 or col7 = 'xxx'&quot;)
</code></pre>

<p>How SHC optimize it? Actually, when filtering on non RowKey, the whole table scan has to be performed. The above query in HSC will get all data from HBase and transfer data to Spark, then filter in Spark. In this case, the performance is limited. Same logic applies to the following query as well.</p>

<pre><code>sqlContext.sql(&quot;select id, col6, col8 from iteblog_table where id = 1 or col7 &lt;= 'xxx'&quot;)
sqlContext.sql(&quot;select id, col6, col8 from iteblog_table where id = 1 or col7 &gt;= 'xxx'&quot;)
sqlContext.sql(&quot;select id, col6, col8 from iteblog_table where col7 = 'xxx'&quot;)
</code></pre>

<p>Obviously, querying in this way is not very effecient. A better way is to push computing to HBase layer using <code>SingleColumnValueFilter</code> to filter as much as possible before moving data to Spark. In this case, we do not have to transfer lots of data from HBase to Spark.</p>

<h4 id="2-composition-rowkey-optimization">2. Composition RowKey Optimization</h4>

<p>SHC also supports Composition as follows：</p>

<pre><code>def cat =
  s&quot;&quot;&quot;{
     |&quot;table&quot;:{&quot;namespace&quot;:&quot;default&quot;, &quot;name&quot;:&quot;iteblog&quot;, &quot;tableCoder&quot;:&quot;PrimitiveType&quot;},
     |&quot;rowkey&quot;:&quot;key1:key2&quot;,
     |&quot;columns&quot;:{
     |&quot;col00&quot;:{&quot;cf&quot;:&quot;rowkey&quot;, &quot;col&quot;:&quot;key1&quot;, &quot;type&quot;:&quot;string&quot;, &quot;length&quot;:&quot;6&quot;},
     |&quot;col01&quot;:{&quot;cf&quot;:&quot;rowkey&quot;, &quot;col&quot;:&quot;key2&quot;, &quot;type&quot;:&quot;int&quot;},
     |&quot;col1&quot;:{&quot;cf&quot;:&quot;cf1&quot;, &quot;col&quot;:&quot;col1&quot;, &quot;type&quot;:&quot;boolean&quot;},
     |&quot;col2&quot;:{&quot;cf&quot;:&quot;cf2&quot;, &quot;col&quot;:&quot;col2&quot;, &quot;type&quot;:&quot;double&quot;},
     |&quot;col3&quot;:{&quot;cf&quot;:&quot;cf3&quot;, &quot;col&quot;:&quot;col3&quot;, &quot;type&quot;:&quot;float&quot;},
     |&quot;col4&quot;:{&quot;cf&quot;:&quot;cf4&quot;, &quot;col&quot;:&quot;col4&quot;, &quot;type&quot;:&quot;int&quot;},
     |&quot;col5&quot;:{&quot;cf&quot;:&quot;cf5&quot;, &quot;col&quot;:&quot;col5&quot;, &quot;type&quot;:&quot;bigint&quot;},
     |&quot;col6&quot;:{&quot;cf&quot;:&quot;cf6&quot;, &quot;col&quot;:&quot;col6&quot;, &quot;type&quot;:&quot;smallint&quot;},
     |&quot;col7&quot;:{&quot;cf&quot;:&quot;cf7&quot;, &quot;col&quot;:&quot;col7&quot;, &quot;type&quot;:&quot;string&quot;},
     |&quot;col8&quot;:{&quot;cf&quot;:&quot;cf8&quot;, &quot;col&quot;:&quot;col8&quot;, &quot;type&quot;:&quot;tinyint&quot;}
     |}
     |}&quot;&quot;&quot;.stripMargin
</code></pre>

<p>In above example, col00 and col01 combined as rowkey，and col00 at first，col01 at last. For example, col00 =&lsquo;row002&rsquo;，col01 = 2，then the composite rowkey is row002\x00\x00\x00\x02。Then when searching Rowkey, how SHC to do optimization? For example, we have following search.</p>

<pre><code>df.sqlContext.sql(&quot;select col00, col01, col1 from iteblog where col00 = 'row000' and col01 = 0&quot;).show()
</code></pre>

<p>Based on the information above，RowKey is composited with col00 and col01. Then，the above search can concat col00 and col01 to form a RowKey，then convert the search to a <strong>get</strong>. However, SHC converts the above search to a <strong>scan</strong> and <strong>get</strong>. The <strong>scan</strong>&rsquo;s startRow is row000 and endRow is row000\xff\xff\xff\xff；<strong>get</strong>&rsquo;s rowkey is row000\xff\xff\xff\xff，then return all data matched the search conditions. In the end, filter in Spark to get the final result. Since SHC is still in development, the solution described above may change.</p>

<p>In SHC, the two query below has the same logic when pushing down to the HBase.</p>

<pre><code>df.sqlContext.sql(&quot;select col00, col01, col1 from iteblog where col00 = 'row000'&quot;).show()
df.sqlContext.sql(&quot;select col00, col01, col1 from iteblog where col00 = 'row000' and col01 = 0&quot;).show()
</code></pre>

<p>The only difference is the filtering in Spark.</p>

<h4 id="2-scan-optimization">2. Scan Optimization</h4>

<p>If we have search conditions, such as &lt; or &gt; as follows：</p>

<pre><code>df.sqlContext.sql(&quot;select col00, col01, col1 from iteblog where col00 &gt; 'row000' and col00 &lt; 'row005'&quot;).show()
</code></pre>

<p>In SHC, this is converted to a <strong>get</strong> and a <strong>scan</strong>. The get&rsquo;s Rowkey is row0005\xff\xff\xff\xff；scan&rsquo;s startRow is row000，endRow is row005\xff\xff\xff\xff，then retun to Spark for fitering.</p>

<p>In summary, SHC can improve the query performance and aviod full table scan. For now this project is merging with <a href="https://github.com/apache/hbase-connectors/">HBase&rsquo;s connectors project</a> for better improvement.</p>

<h2 id="reference">Reference</h2>

<p><a href="https://www.iteblog.com/archives/2522.html">https://www.iteblog.com/archives/2522.html</a></p>

                        </div>
                        
                        
                        <div id="comments">
                            <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "sparkera" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
                        </div>
                        

                    </div>
                    

                    

                    

                    <div class="col-md-3">

                        

                        

<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Search</h3>
    </div>

    <div class="panel-body">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" role="search">
            <div class="input-group">
                <input type="search" name="q" class="form-control" placeholder="Search">
                <input type="hidden" name="sitesearch" value="https://datafibers-community.github.io/">
                <span class="input-group-btn">
                    <button type="submit" class="btn btn-template-main"><i class="fa fa-search"></i></button>
                </span>
            </div>
        </form>
    </div>
</div>







<div class="panel panel-default sidebar-menu">

    <div class="panel-heading">
      <h3 class="panel-title">Categories</h3>
    </div>

    <div class="panel-body">
        <ul class="nav nav-pills nav-stacked">
            
            <li><a href="https://datafibers-community.github.io/categories/article">article (18)</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/categories/digest">digest (10)</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/categories/release">release (3)</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/categories/review">review (1)</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/categories/training">training (1)</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/categories/tutorial">tutorial (1)</a>
            </li>
            
        </ul>
    </div>
</div>








<div class="panel sidebar-menu">
    <div class="panel-heading">
      <h3 class="panel-title">Tags</h3>
    </div>

    <div class="panel-body">
        <ul class="tag-cloud">
            
            <li><a href="https://datafibers-community.github.io/tags/apache"><i class="fa fa-tags"></i> apache</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/big-data"><i class="fa fa-tags"></i> big-data</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/cloud"><i class="fa fa-tags"></i> cloud</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/datafibers"><i class="fa fa-tags"></i> datafibers</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/flink"><i class="fa fa-tags"></i> flink</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/git"><i class="fa fa-tags"></i> git</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/hadoop"><i class="fa fa-tags"></i> hadoop</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/hbase"><i class="fa fa-tags"></i> hbase</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/hive"><i class="fa fa-tags"></i> hive</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/k8s"><i class="fa fa-tags"></i> k8s</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/kafka"><i class="fa fa-tags"></i> kafka</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/machine-learning"><i class="fa fa-tags"></i> machine-learning</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/nosql"><i class="fa fa-tags"></i> nosql</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/redish"><i class="fa fa-tags"></i> redish</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/scala"><i class="fa fa-tags"></i> scala</a>
            </li>
            
            <li><a href="https://datafibers-community.github.io/tags/spark"><i class="fa fa-tags"></i> spark</a>
            </li>
            
        </ul>
    </div>
</div>






                        

                    </div>
                    

                    

                </div>
                

            </div>
            
        </div>
        

        <footer id="footer">
    <div class="container">

        
        <div class="col-md-4 col-sm-6">
            <h4>About us</h4>

            DataFibers are expertises by applying its cutting edge big data technologies and solutions on enterprise big data centric use cases.

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

        <div class="col-md-4 col-sm-6">

             
            <h4>Recent posts</h4>

            <div class="blog-entries">
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="https://datafibers-community.github.io/blog/2021/06/19/2021-06-19-embracing-kubernetes-goodbye-spring-cloud-copy/">
                          
                            <img src="https://datafibers-community.github.io//img/banners/k8s01.png" class="img-responsive" alt="Embracing Kubernetes, Goodbye Spring Cloud">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="https://datafibers-community.github.io/blog/2021/06/19/2021-06-19-embracing-kubernetes-goodbye-spring-cloud-copy/">Embracing Kubernetes, Goodbye Spring Cloud</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="https://datafibers-community.github.io/blog/2021/04/28/2021-04-28-spark-sql-in-depth-copy/">
                          
                            <img src="https://datafibers-community.github.io//img/banners/spark_sql_title.png" class="img-responsive" alt="Spark SQL in Depth">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="https://datafibers-community.github.io/blog/2021/04/28/2021-04-28-spark-sql-in-depth-copy/">Spark SQL in Depth</a></h5>
                    </div>
                </div>
                
                <div class="item same-height-row clearfix">
                    <div class="image same-height-always">
                        <a href="https://datafibers-community.github.io/blog/2021/03/10/2021-03-10-spark-3.3.1-released/">
                          
                            <img src="https://datafibers-community.github.io//img/banners/spark_logo.jpg" class="img-responsive" alt="Apache Spark 3.1.1 Released :)">
                          
                        </a>
                    </div>
                    <div class="name same-height-always">
                        <h5><a href="https://datafibers-community.github.io/blog/2021/03/10/2021-03-10-spark-3.3.1-released/">Apache Spark 3.1.1 Released :)</a></h5>
                    </div>
                </div>
                
            </div>

            <hr class="hidden-md hidden-lg">
             

        </div>
        

        
        <div class="col-md-4 col-sm-6">

          <h4>Contact</h4>

            <p><p><strong>DataFibers.</strong>
        <br>7030 Woodbine Avenue,
        <br>L3R 6G2
        <br>Ontario, Markham
        <br>Canadar
        <br>
        <br>
        <strong>Tel: +1 (647) 960-8578</strong>
        <br></p>


            <a href="/contact" class="btn btn-small btn-template-main">Go to contact page</a>

            <hr class="hidden-md hidden-lg hidden-sm">

        </div>
        
        

    </div>
    
</footer>







<div id="copyright">
    <div class="container">
        <div class="col-md-12">
            
            <p class="pull-left">Copyright (c) 2020, DataFibers all rights reserved.</p>
			<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
		    <span id="busuanzi_container_site_pv"> <span id="busuanzi_value_site_pv"></span> visits</span>
            
            <p class="pull-right">
              Template by <a href="http://bootstrapious.com/free-templates">Bootstrapious</a>.
              

              Powered by <a href="https://gohugo.io/">Hugo</a>
            </p>
        </div>
    </div>
</div>





    </div>
    

    
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-40213017-3', 'auto');
ga('send', 'pageview');
</script>

<script src="//code.jquery.com/jquery-3.1.1.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/Counter-Up/1.0/jquery.counterup.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery-parallax/1.1.3/jquery-parallax.js"></script>

<script src="//maps.googleapis.com/maps/api/js?key=AIzaSyCksU3IZTuUK6fA-doQUfQ4KcYm7mB_vlk&v=3.exp"></script>

<script src="https://datafibers-community.github.io/js/hpneo.gmaps.js"></script>
<script src="https://datafibers-community.github.io/js/gmaps.init.js"></script>
<script src="https://datafibers-community.github.io/js/front.js"></script>


<script src="https://datafibers-community.github.io/js/owl.carousel.min.js"></script>


<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-55ccd57a1c1b9515"></script>
  </body>
</html>
